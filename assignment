
Question 1


Inputs = a, b, c

Given :

u = a * b

v = a * c

w = b + c

F = u + v - w

Solution:

F = (a b) + (a c) - (b + c)

F = a * (b + c) - (b + c)

F = (b + c)(a - 1)

Final value of F in simplest form = (b + c)(a - 1)

Question 2


Inputs = -0.06, -2.5, 1.4

Weights = 2.7, -8.6, 0.002

f(x) = 1/(1+e^-x)

x = -0.06x2.7 + (-2.5)x(-8.6) + 1.4 x 0.002

x = 21.3408

f(x) = sig(21.3408)

f(x) = 0.999999999460

If bias = -1.1

x = 21.3408 - 1.1

x = 20.2408

new f(x) = sig(20.2408)

new f(x) = 0.999999998379

A bias unit is an "extra" neuron added to each pre-output layer that stores the value of 1. Bias units aren't connected to any previous layer and in this sense don't represent a true "activity". A bias value allows you to shift the activation function to the left or right, which may be critical for successful learning.

The bias units are characterized by the text "+1". A bias unit is just appended to the start/end of the input and each hidden layer, and isn't influenced by the values in the previous layer. In other words, these neurons don't have any incoming connections. Bias units still have outgoing connections and they can contribute to the output of the ANN.